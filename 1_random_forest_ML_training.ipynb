{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import geopandas as gpd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import odc.geo  # noqa: F401\n",
    "from odc.stac import load\n",
    "from planetary_computer import sign_url\n",
    "from pystac_client import Client\n",
    "from shapely import geometry\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import predict_xr\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Find and load S2 data\n",
    "\n",
    "Load data and set up your array to use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fiji_bbox = [177.14, -18.41, 179.80, -16.01]\n",
    "fiji_bbox_geometry = geometry.box(*fiji_bbox)\n",
    "\n",
    "fiji_gdf = gpd.GeoDataFrame({'geometry': [fiji_bbox_geometry]}, crs='EPSG:4326')\n",
    "fiji_gdf.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure some things up front\n",
    "chunks = dict(x=2048, y=2048)\n",
    "datetime = \"2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dep_client = Client.open(\"https://stac.staging.digitalearthpacific.org\")\n",
    "\n",
    "collection = \"dep_s2_geomad\"\n",
    "\n",
    "items = list(dep_client.search(\n",
    "    collections=[collection],\n",
    "    bbox=fiji_bbox,\n",
    "    datetime=datetime\n",
    ").items())\n",
    "\n",
    "print(f\"Found {len(items)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S2 bands https://planetarycomputer.microsoft.com/dataset/sentinel-2-l2a\n",
    "\n",
    "bands = [\n",
    "    \"B02\",\n",
    "    \"B03\",\n",
    "    \"B04\",\n",
    "    \"B05\",\n",
    "    \"B06\",\n",
    "    \"B07\",\n",
    "    \"B08\",\n",
    "    \"B8A\",\n",
    "    \"B11\",\n",
    "    \"B12\",\n",
    "    \"emad\",\n",
    "    \"bcmad\",\n",
    "    \"smad\",\n",
    "]\n",
    "\n",
    "data = load(\n",
    "    items,\n",
    "    bbox=fiji_bbox,\n",
    "    measurements=bands,\n",
    "    resolution=10,\n",
    "    chunks=chunks,\n",
    ").squeeze(\"time\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add more indices here...\n",
    "\n",
    "# Incorporate NDVI (Normalised Difference Vegetation Index) = (NIR-red)/(NIR+red)\n",
    "data[\"ndvi\"] = (data[\"B08\"] - data[\"B04\"]) / (data[\"B08\"] + data[\"B04\"])\n",
    "\n",
    "# Incorporate MNDWI (Mean Normalised Difference Water Index) = (Green – SWIR) / (Green + SWIR)\n",
    "data[\"mndwi\"] = (data[\"B03\"] - data[\"B12\"]) / (data[\"B03\"] + data[\"B12\"])\n",
    "\n",
    "# Incorporate EVI (Enhanced Vegetation Index) = 2.5NIR−RED(NIR+6RED−7.5BLUE)+1\n",
    "data[\"evi\"] = (2.5*(data[\"B08\"] - data[\"B04\"]))*((data[\"B08\"] + (6*(data[\"B04\"]) - (7.5*(data[\"B02\"])))))+1\n",
    "\n",
    "# Incorporate SAVI (Standard Vegetation Index) = (800nm−670nm) / (800nm+670nm+L(1+L)) # where L = 0.5\n",
    "data[\"savi\"] = (data[\"B07\"] - data[\"B04\"]) / (data[\"B07\"] + data[\"B04\"] + 0.5*(1 + 0.5))\n",
    "\n",
    "# Incorporate BSI (Bare Soil Index) = ((B11 + B4) - (B8 + B2)) / ((B11 + B4) + (B8 + B2)) # https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/barren_soil/\n",
    "data[\"bsi\"] = ((data[\"B11\"] + data[\"B04\"]) - (data[\"B08\"] + data[\"B02\"])) / ((data[\"B11\"] + data[\"B04\"]) + (data[\"B08\"] + data[\"B02\"])) \n",
    "\n",
    "# Incorporate NDMI (Normalised Difference Moisture Index) # https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/ndmi/\n",
    "data[\"ndmi\"] = ((data[\"B08\"]) - (data[\"B11\"])) / ((data[\"B08\"]) + (data[\"B11\"]))\n",
    "\n",
    "# Incorporate NDBI (Normalised Difference Built-up Index) (B06 - B05) / (B06 + B05); # - built up ratio of vegetation to paved surface - let BU = (ndvi - ndbi) - https://custom-scripts.sentinel-hub.com/custom-scripts/landsat-8/built_up_index/\n",
    "data[\"ndbi\"] = ((data[\"B06\"]) - (data[\"B05\"])) / ((data[\"B06\"]) + (data[\"B05\"]))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add in the DEM from the MSPC https://planetarycomputer.microsoft.com/dataset/cop-dem-glo-30\n",
    "\n",
    "# Authorised access to MPC data.\n",
    "# TODO: rotate key and grab it from an actual environment variable\n",
    "os.environ[\"PC_SDK_SUBSCRIPTION_KEY\"] = \"84162f5502174b1b838239e74a44898d\"\n",
    "\n",
    "mspc_client = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1/\")\n",
    "\n",
    "# Get a pystac client for the MSPC\n",
    "items_dem = list(mspc_client.search(collections=[\"cop-dem-glo-30\"], bbox=fiji_bbox).items())\n",
    "print(len(items_dem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dem = load(\n",
    "    items_dem,\n",
    "    chunks=chunks,\n",
    "    groupby=\"solar_day\",\n",
    "    like=data,\n",
    "    patch_url=sign_url\n",
    ")\n",
    "\n",
    "data_dem = data_dem.where(data_dem != -32768).rename({\"data\":\"elevation\"}).squeeze(\"time\")\n",
    "\n",
    "data_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge DEM with S2 data\n",
    "data_s2_dem = data.update(data_dem)\n",
    "data_s2_dem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and load S1 data\n",
    "\n",
    "Load data and set up your array to use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add S-2 data from DEP\n",
    "items_s1 = list(dep_client.search(collections=[\"dep_s1_mosaic\"], bbox=fiji_bbox, datetime=datetime).items())\n",
    "print(f\"Found {len(items_s1)} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_s1 = load(\n",
    "    items_s1,\n",
    "    bbox=fiji_bbox,\n",
    "    resolution=10,\n",
    "    chunks=chunks,\n",
    "    measurements=[\"mean_vv\", \"mean_vh\"]\n",
    ").squeeze(\"time\")\n",
    "data_s1[\"mean_vv_vh\"] = (data_s1[\"mean_vv\"]) / (data_s1[\"mean_vh\"])\n",
    "\n",
    "data_s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge together all data into an array\n",
    "\n",
    "Merge all collated data and set up your array to use for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged = data_s2_dem.update(data_s1)\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train and predict\n",
    "\n",
    "When you change your training data, you can re-train and predict here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_file = \"training_data/MRD_dissagregated_25.geojson\"\n",
    "\n",
    "tdata = gpd.read_file(training_file, bbox=fiji_bbox_geometry)\n",
    "tdata.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Jesse's way\n",
    "\n",
    "# Get values for each of the image bands at each of the points.\n",
    "pts_proj = tdata.to_crs(merged.odc.crs)\n",
    "\n",
    "# a DataArray with x & y coords\n",
    "pts_da = pts_proj.assign(x=pts_proj.geometry.x, y=pts_proj.geometry.y).to_xarray()\n",
    "\n",
    "# a dataframe or series (for a single point)\n",
    "pt_values_i = (\n",
    "    merged.sel(pts_da[[\"x\", \"y\"]], method=\"nearest\").squeeze().compute().to_pandas()\n",
    ")\n",
    "\n",
    "if isinstance(pt_values_i, pd.Series):\n",
    "    pt_values_i = pt_values_i.to_frame().transpose()\n",
    "    pt_values_i.index = tdata.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_array = pd.concat([tdata, pt_values_i], axis=1).to_crs(4326)\n",
    "training_array = training_array.drop(\n",
    "    columns=[\n",
    "        \"y\",\n",
    "        \"x\",\n",
    "        \"spatial_ref\",\n",
    "        \"time\",\n",
    "        \"fid\",\n",
    "        \"index\",\n",
    "        \"lulc_class\",\n",
    "        \"path\",\n",
    "        \"geometry\",\n",
    "        \"layer\",\n",
    "        \"id\",\n",
    "    ]\n",
    ")\n",
    "# Drop rows where there are any NaNs\n",
    "training_array = training_array.dropna()\n",
    "\n",
    "training_array.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "training_data = np.array(training_array)[:, 1:]\n",
    "classes = np.array(training_array)[:, 0]\n",
    "\n",
    "model = classifier.fit(training_data, classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(model, \"test_model.dump\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filename = 'model_20240209.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "# model = \"model_20240209.dump\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print feature importances against column headings\n",
    "for i in zip(training_array.columns[1:], classifier.feature_importances_):\n",
    "    print(f\"{i[0][0:6]}:\\t {i[1]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
